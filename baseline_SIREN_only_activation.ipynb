{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Imports and Boilerplate\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tensor_to_numpy(tensor: torch.Tensor) -> np.ndarray:\n",
    "    tensor = tensor * 256\n",
    "    tensor[tensor > 255] = 255\n",
    "    tensor[tensor < 0] = 0\n",
    "    tensor = tensor.type(torch.uint8).permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class DIV2K_valid_HR_dataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.img_list = sorted(glob.glob(self.path + \"/*.png\"))[:32]\n",
    "        self.tf = transforms.ToTensor()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_list[idx]\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((512,512))\n",
    "        img_t = self.tf(img)\n",
    "        return img_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DIV2K_valid_HR_dataset(path=\"DIV2K_valid_HR\")\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianFourierFeatureTransform(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    An implementation of Gaussian Fourier feature mapping.\n",
    "\n",
    "    \"Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains\":\n",
    "       https://arxiv.org/abs/2006.10739\n",
    "       https://people.eecs.berkeley.edu/~bmild/fourfeat/index.html\n",
    "\n",
    "    Given an input of size [batches, num_input_channels, width, height],\n",
    "     returns a tensor of size [batches, mapping_size*2, width, height].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_input_channels, mapping_size=256, scale=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self._num_input_channels = num_input_channels\n",
    "        self._mapping_size = mapping_size\n",
    "        self._B = torch.randn((num_input_channels, mapping_size)) * scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.dim() == 4, 'Expected 4D input (got {}D input)'.format(x.dim())\n",
    "\n",
    "        batches, channels, width, height = x.shape\n",
    "\n",
    "        assert channels == self._num_input_channels,\\\n",
    "            \"Expected input to have {} channels (got {} channels)\".format(self._num_input_channels, channels)\n",
    "\n",
    "        # Make shape compatible for matmul with _B.\n",
    "        # From [B, C, W, H] to [(B*W*H), C].\n",
    "        x = x.permute(0, 2, 3, 1).reshape(batches * width * height, channels)\n",
    "\n",
    "        x = x @ self._B.to(x.device)\n",
    "\n",
    "        # From [(B*W*H), C] to [B, W, H, C]\n",
    "        x = x.view(batches, width, height, self._mapping_size)\n",
    "        # From [B, W, H, C] to [B, C, W, H]\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        x = 2 * np.pi * x\n",
    "        return torch.cat([torch.sin(x), torch.cos(x)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cvnote.ddlee.cc/2019/09/12/psnr-ssim-python\n",
    "\n",
    "import math\n",
    "def calculate_psnr(img1, img2):\n",
    "    # img1 and img2 have range [0, 255]\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "    mse = np.mean((img1 - img2)**2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * math.log10(255.0 / math.sqrt(mse))\n",
    "\n",
    "# https://cvnote.ddlee.cc/2019/09/12/psnr-ssim-python\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def ssim(img1, img2):\n",
    "    C1 = (0.01 * 255)**2\n",
    "    C2 = (0.03 * 255)**2\n",
    "\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
    "    window = np.outer(kernel, kernel.transpose())\n",
    "\n",
    "    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n",
    "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
    "    mu1_sq = mu1**2\n",
    "    mu2_sq = mu2**2\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
    "    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
    "    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n",
    "                                                            (sigma1_sq + sigma2_sq + C2))\n",
    "    return ssim_map.mean()\n",
    "\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    '''calculate SSIM\n",
    "    the same outputs as MATLAB's\n",
    "    img1, img2: [0, 255]\n",
    "    '''\n",
    "    if not img1.shape == img2.shape:\n",
    "        raise ValueError('Input images must have the same dimensions.')\n",
    "    if img1.ndim == 2:\n",
    "        return ssim(img1, img2)\n",
    "    elif img1.ndim == 3:\n",
    "        if img1.shape[2] == 3:\n",
    "            ssims = []\n",
    "            for i in range(3):\n",
    "                ssims.append(ssim(img1, img2))\n",
    "            return np.array(ssims).mean()\n",
    "        elif img1.shape[2] == 1:\n",
    "            return ssim(np.squeeze(img1), np.squeeze(img2))\n",
    "    else:\n",
    "        raise ValueError('Wrong input image dimensions.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sin activation\n",
    "\n",
    "class Sine(nn.Module):\n",
    "    def __init__(self, w0 = 1.):\n",
    "        super().__init__()\n",
    "        self.w0 = w0\n",
    "    def forward(self, x):\n",
    "        return torch.sin(self.w0 * x)\n",
    "\n",
    "# siren layer\n",
    "\n",
    "def create_new_model():\n",
    "    model = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                256,\n",
    "                256,\n",
    "                kernel_size=1,\n",
    "                padding=0),\n",
    "            Sine(),\n",
    "            nn.BatchNorm2d(256),\n",
    "\n",
    "            nn.Conv2d(\n",
    "                256,\n",
    "                256,\n",
    "                kernel_size=1,\n",
    "                padding=0),\n",
    "            Sine(),\n",
    "            nn.BatchNorm2d(256),\n",
    "\n",
    "            nn.Conv2d(\n",
    "                256,\n",
    "                256,\n",
    "                kernel_size=1,\n",
    "                padding=0),\n",
    "            Sine(),\n",
    "            nn.BatchNorm2d(256),\n",
    "\n",
    "            nn.Conv2d(\n",
    "                256,\n",
    "                3,\n",
    "                kernel_size=1,\n",
    "                padding=0),\n",
    "            nn.Sigmoid(),\n",
    "\n",
    "        ).to(device)\n",
    "    return model\n",
    "\n",
    "psnr_dict = {}\n",
    "ssim_dict = {}\n",
    "\n",
    "# Note: this can be done outside of the training loop, since the result at this stage is unchanged during the course of training.\n",
    "for ind, img in enumerate(tqdm(dataloader)):\n",
    "    target = img.to(device)\n",
    "    # Create input pixel coordinates in the unit square. This will be the input to the model.\n",
    "    coords = np.linspace(0, 1, target.shape[2], endpoint=False)\n",
    "    xy_grid = np.stack(np.meshgrid(coords, coords), -1)\n",
    "    xy_grid = torch.tensor(xy_grid).unsqueeze(0).permute(0, 3, 1, 2).float().contiguous().to(device)\n",
    "    x = GaussianFourierFeatureTransform(2, 128, 10)(xy_grid)\n",
    "    model = create_new_model()\n",
    "    optimizer = torch.optim.Adam(list(model.parameters()), lr=1e-4)\n",
    "\n",
    "    for epoch in range(2000):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        generated = model(x)\n",
    "\n",
    "        loss = torch.nn.functional.l1_loss(target, generated)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if epoch % 100 == 0:\n",
    "        #     print('Epoch %d, loss = %.03f' % (epoch, float(loss)))\n",
    "        #     plt.imshow(tensor_to_numpy(generated[0]))\n",
    "        #     plt.show()\n",
    "\n",
    "    psnr_dict[ind] = calculate_psnr(tensor_to_numpy(target[0]),tensor_to_numpy(generated[0]))\n",
    "    ssim_dict[ind] = calculate_ssim(tensor_to_numpy(target[0]),tensor_to_numpy(generated[0]))\n",
    "    print(psnr_dict[ind], ssim_dict[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr_total = 0\n",
    "for val in psnr_dict.values():\n",
    "    psnr_total += val\n",
    "psnr_average = psnr_total / len(psnr_dict)\n",
    "psnr_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_total = 0\n",
    "for val in ssim_dict.values():\n",
    "    ssim_total += val\n",
    "\n",
    "ssim_average = ssim_total / len(ssim_dict)\n",
    "ssim_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('baseline_only_sine_activate_psnr_dict.json', 'w') as fp:\n",
    "    json.dump(psnr_dict, fp)\n",
    "with open('baseline_only_sine_activate_ssim_dict.json', 'w') as fp:\n",
    "    json.dump(ssim_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('fourier')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cff626a491088ff6eb8c947a8ca919a57363a7e5fa4daa621ee5be6aeffa2825"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
