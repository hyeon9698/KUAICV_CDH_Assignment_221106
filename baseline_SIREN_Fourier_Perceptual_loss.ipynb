{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":609,"status":"ok","timestamp":1667628507849,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"UpgOPVR5ZPY_","outputId":"0de3f075-b499-4551-d1dc-96b8663e9579"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1996,"status":"ok","timestamp":1667628514137,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"KqOyzIEcZY8b","outputId":"3b44236b-ebe8-4bdd-cf0f-6741f63dd38b"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1667628514138,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"FYt2BZ85ZjZT","outputId":"e01623e5-0f98-4d02-e836-238c471a975d"},"outputs":[],"source":["%cd /content/drive/MyDrive/고려대 컴퓨터 비전 랩실 KUAICV/과제"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":840,"status":"ok","timestamp":1667628516484,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"ovREzC8WZIf1"},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n","\n","from torch.utils.data import Dataset, DataLoader\n","import glob\n","\n","from PIL import Image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1667628516485,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"EZAvUvEkZIf4","outputId":"6e233cc1-0e24-4ba7-b7ea-7fd7fe062d1c"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1667628517227,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"iMqU8ujxZIf5"},"outputs":[],"source":["class SineLayer(nn.Module):\n","    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n","    \n","    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n","    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n","    # hyperparameter.\n","    \n","    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n","    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n","    \n","    def __init__(self, in_features, out_features, bias=True,\n","                 is_first=False, omega_0=30):\n","        super().__init__()\n","        self.omega_0 = omega_0\n","        self.is_first = is_first\n","        \n","        self.in_features = in_features\n","        self.linear = nn.Linear(in_features, out_features, bias=bias)\n","        \n","        self.init_weights()\n","    \n","    def init_weights(self):\n","        with torch.no_grad():\n","            if self.is_first:\n","                self.linear.weight.uniform_(-1 / self.in_features, \n","                                             1 / self.in_features)      \n","            else:\n","                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n","                                             np.sqrt(6 / self.in_features) / self.omega_0)\n","        \n","    def forward(self, input):\n","        return torch.sin(self.omega_0 * self.linear(input))\n","    \n","    \n","class Siren(nn.Module):\n","    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n","                 first_omega_0=30, hidden_omega_0=30.):\n","        super().__init__()\n","        \n","        self.net = []\n","        self.net.append(SineLayer(in_features, hidden_features, \n","                                  is_first=True, omega_0=first_omega_0))\n","\n","        for i in range(hidden_layers):\n","            self.net.append(SineLayer(hidden_features, hidden_features, \n","                                      is_first=False, omega_0=hidden_omega_0))\n","\n","        if outermost_linear:\n","            # final_linear = nn.Sigmoid()\n","            final_linear = nn.Linear(hidden_features, out_features)\n","            \n","            with torch.no_grad():\n","                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n","                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n","                \n","            self.net.append(final_linear)\n","            self.net.append(nn.Sigmoid())\n","        else:\n","            self.net.append(SineLayer(hidden_features, out_features, \n","                                      is_first=False, omega_0=hidden_omega_0))\n","        \n","        self.net = nn.Sequential(*self.net)\n","    \n","    def forward(self, coords):\n","        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n","        output = self.net(coords)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1667628517642,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"9unozGfzZIf6"},"outputs":[],"source":["class GaussianFourierFeatureTransform(torch.nn.Module):\n","    \"\"\"\n","    An implementation of Gaussian Fourier feature mapping.\n","\n","    \"Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains\":\n","       https://arxiv.org/abs/2006.10739\n","       https://people.eecs.berkeley.edu/~bmild/fourfeat/index.html\n","\n","    Given an input of size [batches, num_input_channels, width, height],\n","     returns a tensor of size [batches, mapping_size*2, width, height].\n","    \"\"\"\n","\n","    def __init__(self, num_input_channels, mapping_size=256, scale=10):\n","        super().__init__()\n","\n","        self._num_input_channels = num_input_channels\n","        self._mapping_size = mapping_size\n","        self._B = torch.randn((num_input_channels, mapping_size)) * scale\n","\n","    def forward(self, x):\n","        assert x.dim() == 4, 'Expected 4D input (got {}D input)'.format(x.dim())\n","\n","        batches, channels, width, height = x.shape\n","\n","        assert channels == self._num_input_channels,\\\n","            \"Expected input to have {} channels (got {} channels)\".format(self._num_input_channels, channels)\n","\n","        # Make shape compatible for matmul with _B.\n","        # From [B, C, W, H] to [(B*W*H), C].\n","        x = x.permute(0, 2, 3, 1).reshape(batches * width * height, channels)\n","\n","        x = x @ self._B.to(x.device)\n","\n","        # From [(B*W*H), C] to [B, W, H, C]\n","        x = x.view(batches, width, height, self._mapping_size)\n","        # From [B, W, H, C] to [B, C, W, H]\n","        x = x.permute(0, 3, 1, 2)\n","\n","        x = 2 * np.pi * x\n","        return torch.cat([torch.sin(x), torch.cos(x)], dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1667628518044,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"3rvyoVUXZIf6"},"outputs":[],"source":["class DIV2K_valid_HR_dataset(Dataset):\n","    def __init__(self, path, sidelength):\n","        super().__init__()\n","        self.img_path_list = sorted(glob.glob(path + \"/*.png\"))[:32]\n","        self.transform = Compose([\n","            Resize((sidelength, sidelength)),\n","            ToTensor()\n","        ])\n","\n","    def __len__(self):\n","        return len(self.img_path_list)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.img_path_list[idx]\n","        img = Image.open(img_path)\n","        img = self.transform(img)\n","        self.pixels = img.permute(1, 2, 0).view(-1, 3)\n","        return self.pixels"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1667628518315,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"cu8t_jO2ZIf7"},"outputs":[],"source":["dataset = DIV2K_valid_HR_dataset(path=\"DIV2K_valid_HR\", sidelength=512)\n","dataloader = DataLoader(dataset, batch_size=1, pin_memory=True, num_workers=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1667628518594,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"xx_U8GozZIf7"},"outputs":[],"source":["def get_mgrid(sidelen, dim=2):\n","    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n","    sidelen: int\n","    dim: int'''\n","    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n","    mgrid = torch.stack(torch.meshgrid(*tensors, indexing=\"xy\"), dim=-1)\n","    mgrid = mgrid.reshape(-1, dim)\n","    return mgrid\n","\n","def tensor_to_numpy(tensor: torch.Tensor) -> np.ndarray:\n","    tensor = tensor * 256\n","    tensor[tensor > 255] = 255\n","    tensor[tensor < 0] = 0\n","    tensor = tensor.type(torch.uint8).permute(1, 2, 0).cpu().numpy()\n","    return tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1667628518933,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"B7CcedSBZIf7"},"outputs":[],"source":["# https://cvnote.ddlee.cc/2019/09/12/psnr-ssim-python\n","\n","import math\n","def calculate_psnr(img1, img2):\n","    # img1 and img2 have range [0, 255]\n","    img1 = img1.astype(np.float64)\n","    img2 = img2.astype(np.float64)\n","    mse = np.mean((img1 - img2)**2)\n","    if mse == 0:\n","        return float('inf')\n","    return 20 * math.log10(255.0 / math.sqrt(mse))\n","\n","# https://cvnote.ddlee.cc/2019/09/12/psnr-ssim-python\n","import math\n","import numpy as np\n","import cv2\n","\n","def ssim(img1, img2):\n","    C1 = (0.01 * 255)**2\n","    C2 = (0.03 * 255)**2\n","\n","    img1 = img1.astype(np.float64)\n","    img2 = img2.astype(np.float64)\n","    kernel = cv2.getGaussianKernel(11, 1.5)\n","    window = np.outer(kernel, kernel.transpose())\n","\n","    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n","    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n","    mu1_sq = mu1**2\n","    mu2_sq = mu2**2\n","    mu1_mu2 = mu1 * mu2\n","    sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n","    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n","    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n","\n","    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n","                                                            (sigma1_sq + sigma2_sq + C2))\n","    return ssim_map.mean()\n","\n","\n","def calculate_ssim(img1, img2):\n","    '''calculate SSIM\n","    the same outputs as MATLAB's\n","    img1, img2: [0, 255]\n","    '''\n","    if not img1.shape == img2.shape:\n","        raise ValueError('Input images must have the same dimensions.')\n","    if img1.ndim == 2:\n","        return ssim(img1, img2)\n","    elif img1.ndim == 3:\n","        if img1.shape[2] == 3:\n","            ssims = []\n","            for i in range(3):\n","                ssims.append(ssim(img1, img2))\n","            return np.array(ssims).mean()\n","        elif img1.shape[2] == 1:\n","            return ssim(np.squeeze(img1), np.squeeze(img2))\n","    else:\n","        raise ValueError('Wrong input image dimensions.')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# https://gist.github.com/alper111/8233cdb0414b4cb5853f2f730ab95a49\n","\n","import torch\n","import torchvision\n","\n","class VGGPerceptualLoss(torch.nn.Module):\n","    def __init__(self, resize=True):\n","        super(VGGPerceptualLoss, self).__init__()\n","        blocks = []\n","        blocks.append(torchvision.models.vgg16(pretrained=True).features[:4].eval())\n","        blocks.append(torchvision.models.vgg16(pretrained=True).features[4:9].eval())\n","        blocks.append(torchvision.models.vgg16(pretrained=True).features[9:16].eval())\n","        blocks.append(torchvision.models.vgg16(pretrained=True).features[16:23].eval())\n","        for bl in blocks:\n","            for p in bl.parameters():\n","                p.requires_grad = False\n","        self.blocks = torch.nn.ModuleList(blocks)\n","        self.transform = torch.nn.functional.interpolate\n","        self.resize = resize\n","        self.register_buffer(\"mean\", torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))\n","        self.register_buffer(\"std\", torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))\n","\n","    def forward(self, input, target, feature_layers=[0, 1, 2, 3], style_layers=[]):\n","        if input.shape[1] != 3:\n","            input = input.repeat(1, 3, 1, 1)\n","            target = target.repeat(1, 3, 1, 1)\n","        input = (input-self.mean) / self.std\n","        target = (target-self.mean) / self.std\n","        if self.resize:\n","            input = self.transform(input, mode='bilinear', size=(224, 224), align_corners=False)\n","            target = self.transform(target, mode='bilinear', size=(224, 224), align_corners=False)\n","        loss = 0.0\n","        x = input\n","        y = target\n","        for i, block in enumerate(self.blocks):\n","            x = block(x)\n","            y = block(y)\n","            if i in feature_layers:\n","                loss += torch.nn.functional.l1_loss(x, y)\n","            if i in style_layers:\n","                act_x = x.reshape(x.shape[0], x.shape[1], -1)\n","                act_y = y.reshape(y.shape[0], y.shape[1], -1)\n","                gram_x = act_x @ act_x.permute(0, 2, 1)\n","                gram_y = act_y @ act_y.permute(0, 2, 1)\n","                loss += torch.nn.functional.l1_loss(gram_x, gram_y)\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ASnDxTlLbztB-qn5QkmaY_VfnIFE5je5"},"executionInfo":{"elapsed":474731,"status":"ok","timestamp":1667629824115,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"kXZ2foeCZIf8","outputId":"69ff9503-4e5e-4995-f122-a6a01f273899"},"outputs":[],"source":["psnr_dict = {}\n","ssim_dict = {}\n","for ind, target in enumerate(tqdm(dataloader)):\n","    siren_fourier_model = Siren(in_features=256, out_features=3, hidden_features=256, \n","                  hidden_layers=2, outermost_linear=True).to(device)\n","\n","    optimizer = torch.optim.Adam(lr=1e-4, params=siren_fourier_model.parameters())\n","\n","    # xy_grid = get_mgrid(sidelen=512, dim=2).unsqueeze(0).to(device)\n","    # print(xy_grid.shape)\n","    # break\n","    coords = np.linspace(0, 1, 512, endpoint=False)\n","    xy_grid = np.stack(np.meshgrid(coords, coords), -1)\n","    xy_grid = torch.tensor(xy_grid).unsqueeze(0).permute(0, 3, 1, 2).float().contiguous().to(device)\n","    x = GaussianFourierFeatureTransform(2, 128, 10)(xy_grid)\n","    # import pdb; pdb.set_trace()\n","    x = x.view(1,256,-1)\n","    x = x.permute(0,2,1)\n","\n","    # print(x.shape)\n","    # break\n","    target = target.to(device)\n","    perceptual_loss = VGGPerceptualLoss().to(device)\n","    for step in range(2000):\n","        optimizer.zero_grad()\n","\n","        generated = siren_fourier_model(x)\n","        \n","        loss = perceptual_loss(generated.view(1, 512, 512, 3).permute(0,3,1,2), target.view(1, 512, 512,3).permute(0,3,1,2))\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        # if step % 100 == 0:\n","        #     print(\"Step %d, Total loss %0.6f\" % (step, loss))\n","        #     fig, axes = plt.subplots(1,2, figsize=(12,6))\n","        #     axes[0].imshow(tensor_to_numpy(target[0].cpu().view(512,512,3).permute(2,0,1)))\n","        #     axes[1].imshow(tensor_to_numpy(generated[0].cpu().view(512,512,3).permute(2,0,1)))\n","        #     plt.show()\n","\n","    psnr_dict[ind] = calculate_psnr(tensor_to_numpy(target[0].view(3,512,512).detach()), tensor_to_numpy(generated[0].view(3,512,512).detach()))\n","    ssim_dict[ind] = calculate_ssim(tensor_to_numpy(target[0].view(3,512,512).detach()), tensor_to_numpy(generated[0].view(3,512,512).detach()))\n","    print(psnr_dict[ind], ssim_dict[ind])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1173,"status":"ok","timestamp":1667629825288,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"qqZHr1l-ZIf9","outputId":"118dae62-484e-4606-96d6-047324260166"},"outputs":[],"source":["import torchsummary\n","torchsummary.summary(siren_fourier_model, (262144, 256))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1667629825289,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"-MDv3xLSZIf9","outputId":"0811d57e-ef45-4b2e-97ed-7c02e77b4ca9"},"outputs":[],"source":["psnr_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1667629825289,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"yvkZwX8eZIf9","outputId":"21949fbc-2851-480f-ad02-75c8d3b9f0a4"},"outputs":[],"source":["ssim_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1667629825289,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"Xu2Bc-o4ZIf9","outputId":"b51820da-c9a8-4072-a79b-8282666c199a"},"outputs":[],"source":["psnr_total = 0\n","for val in psnr_dict.values():\n","    psnr_total += val\n","psnr_average = psnr_total / len(psnr_dict)\n","psnr_average"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1667629825290,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"__Es8GK0ZIf-","outputId":"ce4f84dc-19d9-4dc8-c493-21b8cc700fc0"},"outputs":[],"source":["ssim_total = 0\n","for val in ssim_dict.values():\n","    ssim_total += val\n","\n","ssim_average = ssim_total / len(ssim_dict)\n","ssim_average"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1667629825290,"user":{"displayName":"Donghyeon Cho","userId":"06419595930675925007"},"user_tz":-540},"id":"myIoQc99ZIf-"},"outputs":[],"source":["import json\n","\n","with open('baseline_SIREN_Fourier_Perceptual_loss_psnr_dict.json', 'w') as fp:\n","    json.dump(psnr_dict, fp)\n","with open('baseline_SIREN_Fourier_Perceptual_loss_ssim_dict.json', 'w') as fp:\n","    json.dump(ssim_dict, fp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BA0RZVj_ZIf-"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3.7.13 ('fourier')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"cff626a491088ff6eb8c947a8ca919a57363a7e5fa4daa621ee5be6aeffa2825"}}},"nbformat":4,"nbformat_minor":0}
